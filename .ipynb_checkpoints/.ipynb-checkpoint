{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.stats as sts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_parameter_tester(margin, params_list, delta=10000):\n",
    "    ''' Estimates win probability given expected win margin and list of\n",
    "    t-distributions of independent errors.\n",
    "\n",
    "    Arguments:\n",
    "        margin: expected win margin, from -1 to 1\n",
    "        params_list: list of pairs (sigma, degrees of freedom) representing the\n",
    "            parameters for the independent t-distributed random variables to be\n",
    "            added to the expected win margin to get the result\n",
    "        delta: resolution for estimating integral\n",
    "\n",
    "    Output: win probability'''\n",
    "\n",
    "    ## discretize space, convolve a whole bunch of distributions ##\n",
    "\n",
    "    # initialize distribution\n",
    "    convolved = np.asarray([1])\n",
    "\n",
    "    # for each pair of t-distribution parameters\n",
    "    for sigma, deg_f in params_list:\n",
    "\n",
    "        # discretize the region [-1, 1] in delta parts\n",
    "        discretized_space = np.linspace(-1, 1, delta+1)\n",
    "\n",
    "        # find the discretized PDF of the t-distribution given these params\n",
    "        pdf = np.ravel(sts.t.pdf(discretized_space / sigma, deg_f))\n",
    "\n",
    "        # convolve this distribution into convolved\n",
    "        convolved = np.convolve(convolved, pdf)\n",
    "\n",
    "    # set convolved sum to 1, so it is a pdf\n",
    "    convolved = convolved/sum(convolved)\n",
    "\n",
    "    ## find cdf at given margin ##\n",
    "\n",
    "    # find endpoints of intervals of convolved pdf [-endpt, endpt]\n",
    "    endpt = len(params_list)\n",
    "\n",
    "    # find total number of pieces into which the interval is carved\n",
    "    pieces = endpt * delta\n",
    "\n",
    "    # find relative position of margin among the pieces in this interval\n",
    "    pos = pieces * (margin + endpt) / (2*endpt)\n",
    "\n",
    "    # split pos into integer and fracitonal parts\n",
    "    ix = int(np.floor(pos))\n",
    "    frac = pos - ix\n",
    "\n",
    "    # estimate cdf by adding pdf up to this index, principled linear guess\n",
    "    # for the error due to not being right on an index\n",
    "    return sum(convolved[:ix]) + frac * convolved[ix]\n",
    "\n",
    "def generate_summary_stats(results_df):\n",
    "\n",
    "    # filter oddball seats\n",
    "    results = results_df[results_df['ignore'] != True]\n",
    "\n",
    "    # get the states and confidence levels\n",
    "    states = results['state_po'].dropna().unique()\n",
    "    confidences = results['confidence'].dropna().unique()\n",
    "\n",
    "    # initialize a dataframe for statewide and national analysis\n",
    "    sts_df = pd.DataFrame({'STATE' : list(states) + ['USA']}).set_index('STATE')\n",
    "\n",
    "    # for each state\n",
    "    for state, _ in sts_df.iterrows():\n",
    "\n",
    "        # splice results DataFrame to get all results from this state\n",
    "        if state != 'USA':\n",
    "            state_df = results[results['state_po'] == state]\n",
    "        else:\n",
    "            state_df = results\n",
    "\n",
    "        # for each confidence\n",
    "        for conf in confidences:\n",
    "\n",
    "            # splice df to only this confidence\n",
    "            df = state_df[state_df['confidence'] == conf].copy()\n",
    "\n",
    "            # find all outliers (probably surprise uncontesteds)\n",
    "            outliers_df = df[df['win_margin'] > 0.9]\n",
    "            sts_df.loc[state, conf + '_was_uncontested'] = len(outliers_df)\n",
    "\n",
    "            # find all outlier misses\n",
    "            lost_uncontest = outliers_df[outliers_df['correct'] == False]\n",
    "            sts_df.loc[state, conf + '_lost_uncontested'] = len(lost_uncontest)\n",
    "\n",
    "            # delete outliers\n",
    "            df = df[df['win_margin'] <= 0.9]\n",
    "\n",
    "            # find count of races in this category\n",
    "            sts_df.loc[state, conf + '_count'] = len(df)\n",
    "\n",
    "            # find count of races in this category\n",
    "            sts_df.loc[state, conf + '_correct'] = \\\n",
    "                                            len(df[df['correct'] == True])\n",
    "\n",
    "            # find mean winning margin\n",
    "            sts_df.loc[state, conf + '_mean_win_margin'] = \\\n",
    "                                            df['actual_win_margin'].mean()\n",
    "\n",
    "            # find variance of winning margin\n",
    "            sts_df.loc[state, conf + '_variance_win_margin'] = \\\n",
    "                                    df['actual_win_margin'].var()\n",
    "\n",
    "            # if there are races\n",
    "            if len(df) > 0:\n",
    "                # fit t-distribution\n",
    "                deg_f, mean, sigma = sts.t.fit(df['actual_win_margin'])\n",
    "\n",
    "                # save these\n",
    "                sts_df.loc[state, conf + '_t_mean'] = mean\n",
    "                sts_df.loc[state, conf + '_t_sigma'] = sigma\n",
    "                sts_df.loc[state, conf + '_t_deg_f'] = deg_f\n",
    "\n",
    "        conf = 'ALL'\n",
    "        df = state_df.copy()\n",
    "\n",
    "        # find all outliers (probably surprise uncontesteds)\n",
    "        outliers_df = df[df['win_margin'] > 0.9]\n",
    "        sts_df.loc[state, conf + '_was_uncontested'] = len(outliers_df)\n",
    "\n",
    "        # find all outlier misses\n",
    "        outlier_losers_df = outliers_df[outliers_df['correct'] == False]\n",
    "        sts_df.loc[state, conf + '_lost_uncontested'] = len(outlier_losers_df)\n",
    "\n",
    "        # delete outliers\n",
    "        df = df[df['win_margin'] <= 0.9]\n",
    "\n",
    "        # find count of races in this category\n",
    "        sts_df.loc[state, conf + '_count'] = len(df)\n",
    "\n",
    "        # find count of races in this category\n",
    "        sts_df.loc[state, conf + '_correct'] = len(df[df['correct'] == True])\n",
    "\n",
    "        # find mean winning margin\n",
    "        sts_df.loc[state, conf + '_mean_win_margin'] = \\\n",
    "                                        df['actual_win_margin'].mean()\n",
    "\n",
    "        # find variance of winning margin\n",
    "        sts_df.loc[state, conf + '_variance_win_margin'] = \\\n",
    "                                df['actual_win_margin'].var()\n",
    "\n",
    "    return sts_df\n",
    "\n",
    "def get_margins(results, st_stats):\n",
    "    ''' Expected win margin by category, based on 2018 data'''\n",
    "    confidences = results['confidence'].dropna().unique()\n",
    "\n",
    "    # build dictionary of expected win margin by confidence\n",
    "    expected_win_margins = {}\n",
    "    for conf in confidences:\n",
    "        expected_win_margins[conf] = st_stats.loc['USA', conf + '_t_mean']\n",
    "        \n",
    "    return expected_win_margins\n",
    "\n",
    "def add_overperformance(results_df, st_stats):\n",
    "\n",
    "    # filter oddball seats\n",
    "    results = results_df[results_df['ignore'] != True]\n",
    "    \n",
    "    # remove safe seats (uncontested issues)\n",
    "    results = results[results['confidence'] != 'Safe']\n",
    "\n",
    "    # remove predicted I winners\n",
    "    results = results[results['predicted_winner'] != 'I']\n",
    "\n",
    "    expected_win_margins = get_margins(results, st_stats)\n",
    "\n",
    "    # add expected win margin column to results DataFrame\n",
    "    results['expected_win_margin'] = results['confidence'].apply(lambda x: \\\n",
    "           expected_win_margins[x])\n",
    "    \n",
    "    # remove surprise uncontesteds\n",
    "    results = results[results['win_margin'] < 0.9]\n",
    "\n",
    "    # add R overperformance column\n",
    "    results['R_overperformance'] = results.apply(lambda x: \\\n",
    "        x['actual_win_margin'] - x['expected_win_margin'] if \\\n",
    "        x['predicted_winner'] == 'R' else x['expected_win_margin'] - \\\n",
    "        x['actual_win_margin'] if x['predicted_winner'] == 'D' else 0, axis=1)\n",
    "\n",
    "    # find average R_overperformance by state, add column to isolate race effects\n",
    "\n",
    "\n",
    "\n",
    "    # dictionary of mean R_overperformance\n",
    "    R_dict = results.groupby(['state_po'])['R_overperformance'].mean().to_dict()\n",
    "\n",
    "    # add column with these numbers\n",
    "    results['state_R_overperformance'] = results['state_po'].apply(lambda x: \\\n",
    "                                                   R_dict[x])\n",
    "\n",
    "    # add column with isolated error, in direction of GOP\n",
    "    results['isolated_race_error'] = results.apply(lambda x: \\\n",
    "           x['R_overperformance'] - x['state_R_overperformance'], axis=1)\n",
    "\n",
    "    return results\n",
    "\n",
    "def get_density_proportions(results):\n",
    "    columns = ['rural', 'exurban', 'suburban', 'urban']\n",
    "    results['pop'] = results[columns].sum(axis=1)\n",
    "    for col in columns:\n",
    "        results[col + '_prop'] = results[col] / results['pop']\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the 2018 election results, and process to get the R_overperformance from prediction in each district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # set google drive path for files\n",
    "    money_path = 'G:\\\\Shared drives\\\\princeton_gerrymandering_project\\\\Moneyball\\\\'\n",
    "\n",
    "    # read in results\n",
    "    results_df = pd.read_csv(money_path +\\\n",
    "                             'chaz\\\\chaz_with_election_results.csv')\n",
    "    \n",
    "    sts_df = generate_summary_stats(results_df)\n",
    "\n",
    "    results_df = add_overperformance(results_df, sts_df)\n",
    "    \n",
    "    results = add_overperformance(results_df, sts_df)\n",
    "\n",
    "    results = get_density_proportions(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
